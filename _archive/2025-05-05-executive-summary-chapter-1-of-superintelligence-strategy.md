---
title: "Executive Summary — Chapter 1 of Superintelligence Strategy"
tags:
   - Deterrence
   - Nonproliferation
   - National Security
   - AI Security
   - Military Competitiveness
link: https://www.nationalsecurity.ai/chapter/executive-summary
date: 2025-05-05
description: "The rise of advanced AI presents significant national security challenges, comparable to nuclear proliferation. This necessitates a framework of Mutual Assured AI Malfunction (MAIM) for deterrence among states, mirroring nuclear deterrence strategies. To prevent rogue actors from leveraging AI, concepts such as compute security, information security, and AI-specific safeguards are critical. States must also enhance their competitive edge through military adoption of AI, robust domestic chip manufacturing, and legal frameworks for AI governance. The interplay between AI development and security necessitates careful management to prevent destabilization and promote prosperity."
---
{% raw %}

# Executive Summary

Rapid advances in AI are poised to reshape nearly every aspect of society. Governments see in these dual-use AI systems a means to military dominance, stoking a bitter race to maximize AI capabilities. Voluntary industry pauses or attempts to exclude government involvement cannot change this reality. These systems that can streamline research and bolster economic output can also be turned to destructive ends, enabling rogue actors to engineer bioweapons and hack critical infrastructure. “Superintelligent” AI surpassing humans in nearly every domain would amount to the most precarious technological development since the nuclear bomb. Given the stakes, superintelligence is inescapably a matter of national security, and an effective superintelligence strategy should draw from a long history of national security policy.

### Deterrence

A race for AI-enabled dominance endangers all states. If, in a hurried bid for superiority, one state inadvertently loses control of its AI, it jeopardizes the security of all states. Alternatively, if the same state succeeds in producing and controlling a highly capable AI, it likewise poses a direct threat to the survival of its peers. In either event, states seeking to secure their own survival may preventively sabotage competing AI projects. A state could try to disrupt such an AI project with interventions ranging from covert operations that degrade training runs to physical damage that disables AI infrastructure. Thus, we are already approaching a dynamic similar to nuclear Mutual Assured Destruction (MAD), in which no power dares attempt an outright grab for strategic monopoly, as any such effort would invite a debilitating response. This strategic condition, which we refer to as **Mutual Assured AI Malfunction (MAIM)**, represents a potentially stable deterrence regime, but maintaining it could require care. We outline measures to maintain the conditions for MAIM, including clearly communicated escalation ladders, placement of AI infrastructure far from population centers, transparency into datacenters, and more.

### Nonproliferation

While deterrence through MAIM constrains the intent of superpowers, all nations have an interest in limiting the AI capabilities of terrorists. Drawing on nonproliferation precedents for weapons of mass destruction (WMDs), we outline three levers for achieving this. Mirroring measures to restrict key inputs to WMDs such as fissile material and chemical weapons precursors, _compute security_ involves knowing reliably where high-end AI chips are and stemming smuggling to rogue actors. Monitoring shipments, tracking chip inventories, and employing security features like geolocation can help states account for them. States must prioritize _information security_ to protect the model weights underlying the most advanced AI systems from falling into the hands of rogue actors, similar to controls on other sensitive information. Finally, akin to screening protocols for DNA synthesis services to detect and refuse orders for known pathogens, AI companies can be incentivized to implement technical _AI security_ measures that detect and prevent malicious use.

### Competitiveness

Beyond securing their survival, states will have an interest in harnessing AI to bolster their competitiveness, as successful AI adoption will be a determining factor in national strength. Adopting AI-enabled weapons and carefully integrating AI into command and control is increasingly essential for _military_ strength. Recognizing that _economic_ security is crucial for national security, domestic capacity for manufacturing high-end AI chips will ensure a resilient supply and sidestep geopolitical risks in Taiwan. Robust _legal frameworks_ governing AI agents can set basic constraints on their behavior that follow the spirit of existing law. Finally, governments can maintain _political stability_ through measures that improve the quality of decision-making and combat the disruptive effects of rapid automation.

By detecting and deterring destabilizing AI projects through intelligence operations and targeted disruption, restricting access to AI chips and capabilities for malicious actors through strict controls, and guaranteeing a stable AI supply chain by investing in domestic chip manufacturing, states can safeguard their security while opening the door to unprecedented prosperity.

[Executive Summary](https://www.nationalsecurity.ai/chapter/executive-summary)

[AI Is Pivotal for National Security](https://www.nationalsecurity.ai/chapter/ai-is-pivotal-for-national-security)

[Deterrence with Mutual Assured AI Malfunction (MAIM)](https://www.nationalsecurity.ai/chapter/deterrence-with-mutual-assured-ai-malfunction-maim)

[Nonproliferation](https://www.nationalsecurity.ai/chapter/nonproliferation)

[Competitiveness](https://www.nationalsecurity.ai/chapter/competitiveness)

[Conclusion](https://www.nationalsecurity.ai/chapter/conclusion)

[Appendix FAQs](https://www.nationalsecurity.ai/chapter/appendix)

[Introduction](https://www.nationalsecurity.ai/chapter/introduction)

[![](https://cdn.prod.website-files.com/6747c60014d14fc1cba63bde/679d4ad9c7357fc376876ffb_superintelligence%20strategy.svg)](https://www.nationalsecurity.ai/)

[Table of contents](https://www.nationalsecurity.ai/table-of-contents)

[Download Standard Version\\
\\
(10 page PDF)](https://drive.google.com/file/d/1wLcGgLOTVNsVVbgS5lPHOnqOQtNT8Z5j/view) [Download Expert Version\\
\\
(32 page PDF)](https://drive.google.com/file/d/1JVPc3ObMP1L2a53T5LA1xxKXM6DAwEiC/view)

[1\\
\\
Executive Summary](https://www.nationalsecurity.ai/chapter/executive-summary)

[2\\
\\
Introduction](https://www.nationalsecurity.ai/chapter/introduction)

[3\\
\\
AI Is Pivotal for National Security](https://www.nationalsecurity.ai/chapter/ai-is-pivotal-for-national-security)

[3.1\\
\\
Strategic Competition](https://www.nationalsecurity.ai/chapter/ai-is-pivotal-for-national-security#strategic-competition)

[3.1.1\\
\\
Strategic Competition\\
\\
Shifting Basis of Economic Power](https://www.nationalsecurity.ai/chapter/ai-is-pivotal-for-national-security#shifting-basis-of-economic-power)

[3.1.2\\
\\
Strategic Competition\\
\\
Destabilization Through Superweapons](https://www.nationalsecurity.ai/chapter/ai-is-pivotal-for-national-security#destabilization-through-superweapons)

[3.2\\
\\
Terrorism\\
\\
Terrorism](https://www.nationalsecurity.ai/chapter/ai-is-pivotal-for-national-security#terrorism)

[3.2.1\\
\\
Terrorism\\
\\
Bioterrorism](https://www.nationalsecurity.ai/chapter/ai-is-pivotal-for-national-security#bioterrorism)

[3.2.2\\
\\
Terrorism\\
\\
Cyberattacks on Critical Infrastructure](https://www.nationalsecurity.ai/chapter/ai-is-pivotal-for-national-security#cyberattacks-on-critical-infrastructure)

[3.2.3\\
\\
Terrorism\\
\\
Offense-Defense Balance](https://www.nationalsecurity.ai/chapter/ai-is-pivotal-for-national-security#offense-defense-balance)

[3.3\\
\\
Loss of Control\\
\\
Loss of Control](https://www.nationalsecurity.ai/chapter/ai-is-pivotal-for-national-security#loss-of-control)

[3.3.1\\
\\
Loss of Control\\
\\
Erosion of Control](https://www.nationalsecurity.ai/chapter/ai-is-pivotal-for-national-security#erosion-of-control)

[3.3.2\\
\\
Loss of Control\\
\\
Unleashed AI Agents](https://www.nationalsecurity.ai/chapter/ai-is-pivotal-for-national-security#unleashed-ai-agents)

[3.3.3\\
\\
Intelligence Recursion\\
\\
Intelligence Recursion](https://www.nationalsecurity.ai/chapter/ai-is-pivotal-for-national-security#intelligence-recursion)

[3.4\\
\\
Existing AI Strategies\\
\\
Existing AI Strategies](https://www.nationalsecurity.ai/chapter/ai-is-pivotal-for-national-security#existing-ai-strategies)

[4\\
\\
Deterrence with Mutual Assured AI Malfunction (MAIM)](https://www.nationalsecurity.ai/chapter/deterrence-with-mutual-assured-ai-malfunction-maim)

[4.1\\
\\
MAIM Is the Default Regime](https://www.nationalsecurity.ai/chapter/deterrence-with-mutual-assured-ai-malfunction-maim#maim-is-the-default-regime)

[4.2\\
\\
How to Maintain a MAIM Regime](https://www.nationalsecurity.ai/chapter/deterrence-with-mutual-assured-ai-malfunction-maim#how-to-maintain-a-maim-regime)

[5\\
\\
Nonproliferation](https://www.nationalsecurity.ai/chapter/nonproliferation)

[5.1\\
\\
Compute Security](https://www.nationalsecurity.ai/chapter/nonproliferation#compute-security)

[5.1.1\\
\\
Compute Security\\
\\
Export Controls](https://www.nationalsecurity.ai/chapter/nonproliferation#export-controls)

[5.1.2\\
\\
Compute Security\\
\\
Firmware-Level Features](https://www.nationalsecurity.ai/chapter/nonproliferation#firmware-level-features)

[5.2\\
\\
Information Security](https://www.nationalsecurity.ai/chapter/nonproliferation#information-security)

[5.2.1\\
\\
Information Security\\
\\
How to Improve Information Security](https://www.nationalsecurity.ai/chapter/nonproliferation#how-to-improve-information-security)

[5.3\\
\\
AI Security\\
\\
AI Security](https://www.nationalsecurity.ai/chapter/nonproliferation#ai-security)

[5.3.1\\
\\
AI Safeguards\\
\\
Malicious Use](https://www.nationalsecurity.ai/chapter/nonproliferation#malicious-use)

[5.3.2\\
\\
AI Safeguards\\
\\
Loss of Control](https://www.nationalsecurity.ai/chapter/nonproliferation#loss-of-control-745a2)

[6\\
\\
Competitiveness](https://www.nationalsecurity.ai/chapter/competitiveness)

[6.1\\
\\
Military Strength](https://www.nationalsecurity.ai/chapter/competitiveness#military-strength)

[6.2\\
\\
Economic Security](https://www.nationalsecurity.ai/chapter/competitiveness#economic-security)

[6.2.1\\
\\
Economic Security\\
\\
Manufacture AI Chips](https://www.nationalsecurity.ai/chapter/competitiveness#manufacture-ai-chips)

[6.2.3\\
\\
Economic Security\\
\\
Facilitate Immigration for AI Scientists](https://www.nationalsecurity.ai/chapter/competitiveness#facilitate-immigration-for-ai-scientists)

[6.3\\
\\
Legal Frameworks Governing AI Agents](https://www.nationalsecurity.ai/chapter/competitiveness#legal-frameworks-governing-ai-agents)

[6.3.1\\
\\
Legal Frameworks Governing AI Agents\\
\\
Aligning Individual AI Agents](https://www.nationalsecurity.ai/chapter/competitiveness#aligning-individual-ai-agents)

[6.3.2\\
\\
Legal Frameworks Governing AI Agents\\
\\
Aligning Collectives of AI Agents](https://www.nationalsecurity.ai/chapter/competitiveness#aligning-collectives-of-ai-agents)

[6.4\\
\\
Political Stability\\
\\
Political Stability](https://www.nationalsecurity.ai/chapter/competitiveness#political-stability)

[6.4.1\\
\\
Political Stability\\
\\
Censorship and Inaccurate Information](https://www.nationalsecurity.ai/chapter/competitiveness#censorship-and-inaccurate-information)

[6.4.2\\
\\
Political Stability\\
\\
Automation](https://www.nationalsecurity.ai/chapter/competitiveness#automation)

[7\\
\\
Conclusion\\
\\
Conclusion](https://www.nationalsecurity.ai/chapter/conclusion)

[8\\
\\
Appendix: FAQs](https://www.nationalsecurity.ai/chapter/appendix)
{% endraw %}
