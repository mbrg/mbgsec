---
title: "OpenAI: Explainability and reasoning should inform future AI models ◆ VentureBeat"
tags:
   - responsible AI
   - OpenAI
   - neural networks
   - machine learning
   - AI explainability
link: https://venturebeat.com/ai/openai-explainability-and-reasoning-should-inform-future-ai-models/
date: 2025-05-09
description: "OpenAI's advancements in AI research highlight a critical focus on explainability and ethical deployment to mitigate risks associated with powerful AI systems. The firm emphasizes the need for transparency in model architectures, illustrated through their activation atlas technique. The ongoing strategy aims to cultivate community norms around responsible AI publication due to concerns over dual-use technologies, such as deepfakes. Collaborative industry efforts are deemed essential for enhancing safety standards, ensuring that AI applications remain beneficial while preventing misuse. This approach signals a proactive stance in developing AI systems that are not only innovative but also ethically grounded."
---
{% raw %}

[Skip to main content](https://venturebeat.com/ai/openai-explainability-and-reasoning-should-inform-future-ai-models/#primary)

_Join our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage. [Learn More](https://venturebeat.com/newsletters/?utm_source=VBsite&utm_medium=desktopNav)_

* * *

OpenAI conducts an enormous amount of research in AI subfields from computer vision to natural language processing (NLP). The San Francisco-based firm — which was cofounded by CTO Greg Brockman, chief scientist Ilya Sutskever, and others with a $1 billion in backing from luminaries like LinkedIn cofounder Reid Hoffman and Sam Altman — last year detailed an AI robotics system capable of human-like [dexterity](https://venturebeat.com/2018/07/30/openais-state-of-the-art-system-gives-robots-humanlike-dexterity/). The capped-profit company’s Dota 2 [bot](https://venturebeat.com/2019/04/13/openai-five-defeats-a-team-of-professional-dota-2-players/) recently defeated 99.4% of players in public matches and a [team](https://venturebeat.com/2019/04/13/openai-five-defeats-a-team-of-professional-dota-2-players/) of professional players twice, and its most sophisticated NLP model can generate convincingly humanlike short stories and Amazon reviews from whole cloth.

Unsurprisingly, there’s been a lot of learnings in the roughly three and a half years since OpenAI’s inception. At VentureBeat’s Transform 2019 conference, Brockman and Sutskever touched on advances in hardware and transparency with respect to AI, and on the topic of responsible disclosure.

Securing the Super Bowl

Brockman said the uptick in raw compute has been the single most important driver of AI advances in the past seven years. “The amount of compute that’s been going into these models has increased by a factor of 10 each year since 2012,” he said. “It’s a little like if your cell phone battery, which today lasts for a day, five years later lasts for 800 years and another five years later lasts for 100 million years.”

That’s obviously exciting, added Brockman, but fraught with peril. He’s not the only one who thinks so. Last September, members of Congress sent a letter to National Intelligence director Dan Coats requesting a report from intelligence agencies about the potential impact on democracy and national security of deepfakes, or videos created using AI that digitally grafts faces onto other people’s bodies. And during a congressional hearing in late 2018, members of Congress speaking with Facebook COO Sheryl Sandberg and Twitter CEO Jack Dorsey also expressed concerns about the potential impact of manipulative deepfake videos.

“You have to ask, what are the risks? How can this go wrong?” said Brockman. “How can we make sure that we’re applying the right ethics and building this technology in the right way?”

That’s why OpenAI decided last year not to release the corpus used to train the aforementioned NLP model, nor three of the four language models or the training code. At the time, the company said it believed making available the unfettered toolset might open the door to abusive behavior by bad actors.

Greg Brockman & Ilya Sutskever \| Mainstage \| VB Transform 2019 - YouTube

VentureBeat

22.6K subscribers

[Greg Brockman & Ilya Sutskever \| Mainstage \| VB Transform 2019](https://www.youtube.com/watch?v=-j_48VkO8cs)

VentureBeat

Search

Info

Shopping

Tap to unmute

If playback doesn't begin shortly, try restarting your device.

You're signed out

Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.

CancelConfirm

Share

Include playlist

An error occurred while retrieving sharing information. Please try again later.

Watch later

Share

Copy link

Watch on

0:00

0:00 / 24:58
•Live

•

[Watch on YouTube](https://www.youtube.com/watch?v=-j_48VkO8cs "Watch on YouTube")

According to Brockman, one goal of the decision was to stimulate discussion in the AI community about responsible publication. He believes the worst-case scenario is the release of a model whose catastrophic effects force a reactionary response.

“We created an AI system with capabilities that really surprised us, and it was hard for us to assess what it’d be used for and what the limits of it should be,” said Brockman. “The argument that really tipped it for us … is that as this technology progresses, we’re going to have models with dual-use applications. They can have amazing \[uses\] and do great things, but only if they’re used in the right way.”

He added: “You really need to have a dry run. That’s why it was really important to us that we \[developed\] a norm for how you can not share.”

Explainability is perhaps the key. AI systems that can justify their predictions — systems which OpenAI is actively developing — could help peel back the curtains on particularly opaque architectures, said Brockman. In March, OpenAI and Google open-sourced a technique that lays bare the component interactions within image-classifying neural networks. They call the visualization an [activation atlas](https://venturebeat.com/2019/03/06/openai-and-google-detail-activation-atlases-a-technique-for-visualizing-ai-decision-making/), and they say it’s intended to illustrate how those interactions shape the model’s decision-making.

“Explainability in neural networks is an incredibly important question, because as neural networks become smarter, it would become preferable to understand why they make particular predictions,” said Sutskever. “What I would expect to see longer-term, as this work advances, is that we apply \[explainability\] tools to language model and models in other domains, and when we can use the model’s language abilities to explain to use its decisions. That will be very useful.”

Commonsense reasoning might be another piece of the puzzle. Brockman and Sutskever are leading a new team at OpenAI aptly dubbed the Reasoning Team, with the aim of imbuing machine learning models with the ability to reason through and solve tasks they can’t today.

“There’s this myth that neural nets are a black box,” said Brockman. “The hope is that we can understand why it’s making the decisions that it is, and ensure that it’s actually going to do what we think it’s going to do, and we can then ensure that it’s actually used to benefit people.”

Ultimately, it’ll require industry collaboration. To this end, OpenAI today published a [blog post](https://openai.com/blog/cooperation-on-safety/) and accompanying paper outlining strategies — like increasing transparency about investments and committing to higher standards — that can be used to improve the likelihood of long-term industry cooperation on safety norms in AI. The coauthors posit that this sort of collaboration will be “instrumental” in ensuring AI systems are both safe and beneficial, particularly in competitive environments that could cause companies to under-invest in safety.

“I view what \[we’re doing\] as a first step toward informing community norms, and my hope is that they’re now starting to fall into place,” said Brockman.

**Daily insights on business use cases with VB Daily**

If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.

Subscribe Now

Read our [Privacy Policy](https://venturebeat.com/terms-of-service/)

Thanks for subscribing. Check out more [VB newsletters here](https://venturebeat.com/newsletters/).


An error occured.

![](https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png)

×

![](https://venturebeat.com/wp-content/themes/vb-news/brand/img/AI-Weekly.png)

### The AI insights you need to lead

Submit

Thanks for subscribing. Check out more [VB newsletters here](https://venturebeat.com/newsletters/).


An error occured.

![](https://pixel.wp.com/g.gif?v=ext&blog=126020344&post=2513040&tz=-7&srv=venturebeat.com&hp=vip&j=1%3A14.5&host=venturebeat.com&ref=&fcp=0&rand=0.012923553190447024)![](https://ids4.ad.gt/api/v1/ip_match?id=AU1D-0100-001746802544-2L2EWWHV-2HWM)![](https://secure.adnxs.com/getuid?https://ids.ad.gt/api/v1/match?id=AU1D-0100-001746802544-2L2EWWHV-2HWM&adnxs_id=$UID&gdpr=0)![](https://u.openx.net/w/1.0/cm?id=998eaf06-9905-4eae-9e26-9fac75960c53&r=https%3A%2F%2Fids.ad.gt%2Fapi%2Fv1%2Fopenx%3Fopenx_id%3D%7BOPENX_ID%7D%26id%3DAU1D-0100-001746802544-2L2EWWHV-2HWM%26auid%3DAU1D-0100-001746802544-2L2EWWHV-2HWM)![](https://image2.pubmatic.com/AdServer/UCookieSetPug?rd=https%3A%2F%2Fids.ad.gt%2Fapi%2Fv1%2Fpbm_match%3Fpbm%3D%23PM_USER_ID%26id%3DAU1D-0100-001746802544-2L2EWWHV-2HWM)![](https://token.rubiconproject.com/token?pid=50242&puid=AU1D-0100-001746802544-2L2EWWHV-2HWM&gdpr=0)![](https://match.adsrvr.org/track/cmf/generic?ttd_pid=8gkxb6n&ttd_tpi=1&ttd_puid=AU1D-0100-001746802544-2L2EWWHV-2HWM&gdpr=0)![](https://pixel.tapad.com/idsync/ex/receive?partner_id=3185&partner_device_id=AU1D-0100-001746802544-2L2EWWHV-2HWM&partner_url=https://ids.ad.gt%2Fapi%2Fv1%2Ftapad_match%3Fid%3DAU1D-0100-001746802544-2L2EWWHV-2HWM%26tapad_id%3D%24%7BTA_DEVICE_ID%7D)![](https://cm.g.doubleclick.net/pixel?google_nid=audigent_w_appnexus_3985&google_cm&google_sc&google_ula=450542624&id=AU1D-0100-001746802544-2L2EWWHV-2HWM)![](https://d.turn.com/r/dd/id/L2NzaWQvMS9jaWQvMTc0ODI0MTY1OC90LzA/url/https%3A%2F%2Fids.ad.gt%2Fapi%2Fv1%2Famo_match%3Fturn_id%3D%24!%7BTURN_UUID%7D%26id%3DAU1D-0100-001746802544-2L2EWWHV-2HWM)![](https://sync.go.sonobi.com/us?https://ids.ad.gt/api/v1/son_match?id=AU1D-0100-001746802544-2L2EWWHV-2HWM&uid=[UID]&gdpr=0)![](https://ids.ad.gt/api/v1/g_hosted?id=AU1D-0100-001746802544-2L2EWWHV-2HWM)
{% endraw %}
