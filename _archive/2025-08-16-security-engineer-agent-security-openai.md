---
date: '2025-08-16'
description: OpenAI is seeking a Security Engineer for its Agent Security Team in
  San Francisco to enhance the safeguarding of agentic AI systems. Key responsibilities
  include architecting security controls, developing production-grade safety monitoring
  tools, and collaborating with cross-functional teams to balance security, performance,
  and usability. Candidates must demonstrate proficiency in Python or a systems language,
  possess expertise in isolation techniques and network security, and have cloud security
  experience. This role is pivotal in shaping rigorous security practices for advanced
  AI technologies. Compensation ranges from $325K to $495K plus equity.
link: https://openai.com/careers/security-engineer-agent-security/
tags:
- cloud-security
- security-engineering
- network-security
- software-development
- agentic-ai
title: Security Engineer, Agent Security ◆ OpenAI
---
{% raw %}

Switch to

- [ChatGPT(opens in a new window)](https://chatgpt.com/?openaicom-did=e1c7ec5f-9971-4846-b4a4-6bcb51153ed3&openaicom_referred=true)
- [Sora(opens in a new window)](https://sora.com/)
- [API Platform(opens in a new window)](https://platform.openai.com/)

Security Engineer, Agent Security \| OpenAI

Careers

## Security Engineer, Agent Security

Security - San Francisco

[Apply now(opens in a new window)](https://jobs.ashbyhq.com/openai/e9bea775-7eb6-438a-ab96-27d5f941e69d/application)

**About the Team**

The team’s mission is to accelerate the secure evolution of agentic AI systems at OpenAI. To achieve this, the team designs, implements, and continuously refines security policies, frameworks, and controls that defend OpenAI’s most critical assets—including the user and customer data embedded within them—against the unique risks introduced by agentic AI.

**About the Role**

**As a Security Engineer on the Agent Security Team**, you will be at the forefront of securing OpenAI’s cutting-edge agentic AI systems. Your role will involve designing and implementing robust security frameworks, policies, and controls to safeguard OpenAI’s critical assets and ensure the safe deployment of agentic systems. You will develop comprehensive threat models, partner tightly with our Agent Infrastructure group to fortify the platforms that power OpenAI’s most advanced agentic systems, and lead efforts to enhance safety monitoring pipelines at scale.

We are looking for a versatile engineer who thrives in ambiguity and can make meaningful contributions from day one. You should be prepared to ship solutions quickly while maintaining a high standard of quality and security.

We’re looking for people who can drive innovative solutions that will set the industry standard for agent security. You will need to bring your expertise in securing complex systems and designing robust isolation strategies for emerging AI technologies, all while being mindful of usability. You will communicate effectively across various teams and functions, ensuring your solutions are scalable and robust while working collaboratively in an innovative environment. In this fast-paced setting, you will have the opportunity to solve complex security challenges, influence OpenAI’s security strategy, and play a pivotal role in advancing the safe and responsible deployment of agentic AI systems.

This role is based in **San Francisco, CA**. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.

**You’ll be responsible for:**

- Architecting security controls for agentic AI – design, implement, and iterate on identity, network, and runtime-level defenses (e.g., sandboxing, policy enforcement) that integrate directly with the Agent Infrastructure stack.

- Building production-grade security tooling – ship code that hardens safety monitoring pipelines across agent executions at scale.

- Collaborating cross-functionally – work daily with Agent Infrastructure, product, research, safety, and security teams to balance security, performance, and usability.

- Influencing strategy & standards – shape the long-term Agent Security roadmap, publish best practices internally and externally, and help define industry standards for securing autonomous AI.


**We’re looking for someone with:**

- Strong software-engineering skills in Python or at least one systems language (Go, Rust, C/C++), plus a track record of shipping and operating secure, high-reliability services.

- Deep expertise in modern isolation techniques – experience with container security, kernel-level hardening, and other isolation methods.

- Hands-on network security experience – implementing identity-based controls, policy enforcement, and secure large-scale telemetry pipelines.

- Clear, concise communication that bridges engineering, research, and leadership audiences; comfort influencing roadmaps and driving consensus.

- Bias for action & ownership – you thrive in ambiguity, move quickly without sacrificing rigor, and elevate the security bar company-wide from day one.

- Cloud security depth on at least one major provider (Azure, AWS, GCP), including identity federation, workload IAM, and infrastructure-as-code best practices.

- Familiarity with AI/ML security challenges – experience addressing risks associated with advanced AI systems (nice-to-have but valuable).


**About OpenAI**

OpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.

We are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.

For additional information, please see [OpenAI’s Affirmative Action and Equal Employment Opportunity Policy Statement](https://cdn.openai.com/policies/eeo-policy-statement.pdf).

Qualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.

To notify OpenAI that you believe this job posting is non-compliant, please submit a report through [this form](https://form.asana.com/?d=57018692298241&k=5MqR40fZd7jlxVUh5J-UeA). No response will be provided to inquiries unrelated to job posting compliance.

We are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this [link](https://form.asana.com/?k=bQ7w9h3iexRlicUdWRiwvg&d=57018692298241).

[OpenAI Global Applicant Privacy Policy](https://cdn.openai.com/policies/global-employee-and-contractor-privacy-policy.pdf)

At OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.

**Compensation**

$325K – $495K + Offers Equity

[Apply now(opens in a new window)](https://jobs.ashbyhq.com/openai/e9bea775-7eb6-438a-ab96-27d5f941e69d/application)
{% endraw %}
