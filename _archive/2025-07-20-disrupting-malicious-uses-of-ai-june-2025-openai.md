---
title: "Disrupting malicious uses of AI: June 2025 | OpenAI"
tags:
   - Malicious AI Uses
   - AI Safety
   - Technology Policy
   - Ethical AI
   - Cybersecurity
link: https://openai.com/global-affairs/disrupting-malicious-uses-of-ai-june-2025/
date: 2025-07-20
description: "OpenAI's June 2025 report outlines advancements in combating malicious AI applications. Key initiatives include developing AI tools that detect and disrupt activities such as social engineering, cyber espionage, and covert influence operations. The report emphasizes the importance of establishing protective regulations against authoritarian misuse and leveraging AI to enhance investigative capabilities in cybersecurity. This proactive approach aims to ensure AI contributes positively by mitigating real-world threats and promoting democratic values. For further insights, refer to the full report [here](https://cdn.openai.com/threat-intelligence-reports/5f73af09-a3a3-4a55-992e-069237681620/disrupting-malicious-uses-of-ai-june-2025.pdf)."
---
{% raw %}

Switch to

- [ChatGPT(opens in a new window)](https://chatgpt.com/?openaicom-did=df0fcc59-526d-4aaa-84af-b57191050945&openaicom_referred=true)
- [Sora(opens in a new window)](https://sora.com/)
- [API Platform(opens in a new window)](https://platform.openai.com/)

OpenAI

June 5, 2025

[Global Affairs](https://openai.com/news/global-affairs/)

# Disrupting malicious uses of AI: June 2025

Our latest report featuring case studies of how we’re detecting and preventing malicious uses of AI.

![Soft pastel abstract background with blended shades of pink, purple, and blue.](https://images.ctfassets.net/kftzwdyauwt9/2oBsxrIQx8AyX80a0AFuDX/4646c7c929b849fdac9d40903628668b/Wallpaper.png?w=3840&q=90&fm=webp)

Loading…

Share

Our mission is to ensure that artificial general intelligence benefits all of humanity. We advance this mission by deploying our innovations to build AI tools that help people solve really hard problems.

As we laid out in [our submission⁠](https://openai.com/global-affairs/openai-proposals-for-the-us-ai-action-plan/) to the Office of Science and Technology Policy’s U.S. AI Action Plan in March, we believe that making sure AI benefits the most people possible means enabling AI through common-sense rules aimed at protecting people from actual harms, and building democratic AI. This includes preventing the use of AI tools by authoritarian regimes to amass power and control their citizens, or to threaten or coerce other states; as well as activities such as covert influence operations (IO), child exploitation, scams, spam, and malicious cyber activity.

It also includes _using_ AI to develop groundbreaking new tools for those who defend against such abuses. By using AI as a force multiplier for our expert investigative teams, in the three months since our last report we’ve been able to detect, disrupt, and expose abusive activity including social engineering, cyber espionage, deceptive employment schemes, covert influence operations and scams.

- [Read the full report(opens in a new window)](https://cdn.openai.com/threat-intelligence-reports/5f73af09-a3a3-4a55-992e-069237681620/disrupting-malicious-uses-of-ai-june-2025.pdf)

- [2025](https://openai.com/news/?tags=2025)
- [Policies and Procedures](https://openai.com/news/?tags=policies-procedures)

## Author

[OpenAI](https://openai.com/news/?author=openai#results)
{% endraw %}
